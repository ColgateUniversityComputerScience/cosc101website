<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>hw9</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<h1 id="cosc-101-homework-9-fall-2021">COSC 101 Homework 9; Fall 2022</h1>
<p>The due date for this homework is <strong>Thursday, April 28, 5:00pm EDT</strong>.</p>
<p>This assignment is designed to give you practice with the following topics:</p>
<ul>
<li>Program design</li>
<li>File I/O</li>
<li>Lists</li>
<li>Dictionaries</li>
<li>Exceptions</li>
</ul>
<h1 id="introduction">Introduction</h1>
<p><strong>Sentiment Analysis</strong> is the machine learning task of determining the opinion conveyed in a piece of text. For example, sentiment analysis can be used to determine whether a written product review is positive, negative, or neutral.</p>
<p>Many approaches have been used for sentiment analysis. The simplest approach uses a lexicon – a dictionary where words are associated with sentiments. For example, words like good and excellent are associated with a positive sentiment, while words like wrong and awful are associated with negative sentiment. The sentiment of the entire text is given by the count of positive and negative words. The sentence is positive if there are more positive than negative words; negative if there are more negative than positive words, and neutral if there is a tie.</p>
<p>In this homework, you will complete a program that uses emojis for sentiment analysis. This will involve processing existing texts (tweets!) to build a lexicon and then using this lexicon to predict the emojis that likely apply to new texts.</p>
<h1 id="instructions">Instructions</h1>
<p>Download <a href="hw9.zip"><code>hw9.zip</code></a> and unzip the compressed file to reveal the following files included with this assignment:</p>
<ul>
<li><code>hw9.pdf</code>: this description</li>
<li><code>data.txt</code>: file with one text (tweet) per line</li>
<li><code>hw9.py</code>: starting code</li>
</ul>
<p>All of your work for this assignment will be completed in the file <code>hw9.py</code>. As with other assignments, this file has a special header at the top with form fields that you should fill out before submitting the code for this assignment. Also, do not change the file name, as we sometimes use programs to test your code. These test programs will not be able to find your program and give you any credit if your file is named incorrectly.</p>
<h2 id="required-functionality">Required functionality</h2>
<p>This homework is split into five steps. You will need to implement a function for three of the five steps. These functions are <code>create_training_set</code>, <code>bag_of_words</code> and <code>main</code>.</p>
<p>For <code>create_training_set</code> and <code>bag_of_words</code>, there are provided doctests that can help you test your program. We strongly recommend using the provided doctests and writing your own doctests to test other cases. You can run the doctests for all functions in the <code>hw9.py</code> file with the following command:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="ex">python</span> <span class="at">-m</span> doctest hw9.py</span></code></pre></div>
<p>Running the doctest with the provided starter code (before you start programming) will produce 5 failures, most of them corresponding to runtime exceptions.</p>
<h2 id="step-1-create-the-dataset">Step 1: Create the dataset</h2>
<p>The <code>create_training_set</code> function should convert a list of texts containing emojis into a dictionary. The dictonary should have emoji keys and values that are lists of texts with emojis removed.</p>
<p>For example, if the list contains only three texts</p>
<pre><code>[&quot;axa 🙏 bb 🥰&quot;, &quot;🥰 cc axa&quot;, &quot;xx 🥺 z&quot;]</code></pre>
<p>the <code>create_training_set</code> function should produce the dictionary</p>
<pre><code>{&#39;🙏&#39;: [&#39;axa  bb &#39;], &#39;🥰&#39;: [&#39;axa  bb &#39;, &#39; cc axa&#39;], &#39;🥺&#39;: [&#39;xx  z&#39;]}</code></pre>
<p>This is because the 🥰 emoji occurred in texts <code>'axa bb'</code> and <code>' cc axa'</code> with emojis removed.</p>
<p>You only need to worry about the emojis included in the <code>EMOJIS</code> list at the top of the <code>hw9.py</code> file. These commonly-used emojis are the only ones that will appear in the dataset you will use for sentiment analysis.</p>
<p>Remember to use the provided doctest for the <code>create_training_set</code> function to test your code. You are also encouraged to add additional doctests to test other cases.</p>
<h2 id="step-2-word-count">Step 2: Word Count</h2>
<p>The <code>bag_of_words</code> function should count the number of times any given word occurs in a list of texts. This produces a “bag of words” model which only considers the number of each word and not the word order.</p>
<p>For example, if <code>bag_of_words</code> is given the list</p>
<pre><code>[&#39;axa bb &#39;, &#39;bb z&#39;]</code></pre>
<p>it should produce the dictionary</p>
<pre><code>{&#39;axa&#39;: 1, &#39;bb&#39;: 2, &#39;z&#39;:1}</code></pre>
<p>because the word <code>'bb'</code> occurs twice across the texts in the list. You can assume that words will be separated by spaces.</p>
<p>Remember to use the provided doctest for the <code>bag_of_words</code> function to test your code. You are also encouraged to add additional doctests to test other cases.</p>
<h2 id="step-3-training-provided">Step 3: Training (Provided)</h2>
<p>The <code>train</code> function, which has been provided for you, applies the <code>bag_of_words</code> function to the output of the <code>create_training_set</code> function.</p>
<p>For example, let</p>
<pre><code>{&#39;🙏&#39;: [&#39;axa bb &#39;, &#39;bb z&#39;], &#39;🥰&#39;: [&#39; cc axa&#39;], &#39;🥺&#39;: [&#39;xx z&#39;]}</code></pre>
<p>be the output of <code>create_training_set</code>. The <code>train</code> function will take this dictionary and produce</p>
<pre><code>{&#39;🙏&#39;: {&#39;axa&#39;: 1, &#39;bb&#39;: 2, &#39;z&#39;:1},  &#39;🥰&#39;: {&#39;cc&#39;:1 , &#39;axa&#39;: 1}, &#39;🥺&#39;: {&#39;xx&#39;: 1, &#39;z&#39;: 1}}</code></pre>
<p>where the lists of texts have been converted into dictionaries of word counts.</p>
<p><strong>Reminder:</strong> You do not need to modify anything in <code>train</code>. If you have implemented <code>create_training_set</code> and <code>bag_of_words</code> correctly, the <code>train</code> doctests will pass.</p>
<h2 id="step-4-prediction-provided">Step 4: Prediction (Provided)</h2>
<p>The <code>predict</code> function, which has been provided for you, takes a trained model and a new text without emojis. The function predicts what emojis most likely apply to the text. It does this by matching the words in the text to the words in the dictionaries <code>train</code>. Trace through the <code>predict</code> function to make sure you understand how it works.</p>
<p><strong>Reminder:</strong> You do not need to modify anything in <code>predict</code>. If you have implemented <code>create_training_set</code> and <code>bag_of_words</code> correctly, the <code>predict</code> doctests will pass</p>
<h2 id="step-5-main-function">Step 5: main() function</h2>
<p>The final step is to create a <code>main</code> function that does the following:</p>
<ol type="1">
<li>Read a list of texts stored in a file called <code>data.txt</code>. The file has one text per line, and each text contains at least one emoji</li>
<li>Use the <code>train</code> function to create a model from the list of texts</li>
<li>Iteratively asks the user to provide a new text and use the <code>predict</code> function to predict what emojis best fit the text</li>
<li>Print the predicted emojis to the screen</li>
</ol>
<p>For example, if the user enters</p>
<pre><code>HI everyone, Good afternoon</code></pre>
<p>when prompted, the program should print</p>
<pre><code>{&#39;😭&#39;: 1, &#39;😍&#39;: 1, &#39;🥰&#39;: 3, &#39;🙏&#39;: 2, &#39;🤣&#39;: 1}</code></pre>
<p>To indicate that the 🥰 emoji is the best fit for the text, while the others are slightly worse fits.</p>
<h1 id="submission-instructions">Submission Instructions</h1>
<p>Please upload your <code>hw9.py</code> file.</p>
<p>Remember to complete the questions at the top of the <code>hw9.py</code> file and that the file you submit needs to have this exact filename.</p>
<h1 id="grading">Grading</h1>
<p>Your assignment will be graded on two criteria:</p>
<ol type="1">
<li><p>Correctness: [75%]. The correctness part of your grade is broken down as follows:</p>
<table>
<thead>
<tr class="header">
<th>Category (function)</th>
<th>Portion of grade</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Correctly create the training set</td>
<td>30%</td>
</tr>
<tr class="even">
<td>Correctly train the model</td>
<td>30%</td>
</tr>
<tr class="odd">
<td>Correctly develop the main function</td>
<td>15%</td>
</tr>
</tbody>
</table></li>
<li><p>Program design and style [25%]. For this assignment, you are tasked with completing three functions within each function:</p>
<ul>
<li><p>Variable names should be meaningful</p></li>
<li><p>Code should contain at least a few descriptive comments if it is complex. Do <em>not</em> comment every line of code with low level explanations of what each line does. Focus on high level ideas. You will <strong>lose points</strong> if you document every line of the file.</p></li>
<li><p>Functions should contain meaningful docstrings.</p></li>
</ul></li>
</ol>
<h2 id="academic-integrity-note">Academic Integrity Note</h2>
<p>The instructors are aware that there are “solutions” for some aspects of this homework on Internet sites. Remember that copying code from such “solutions” is against syllabus policies and constitutes an academic honor code violation.</p>
</body>
</html>
